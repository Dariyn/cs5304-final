{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import dateutil.parser\n",
    "from tqdm.auto import tqdm \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns \n",
    "import plotly.offline as pyo \n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import scattertext as st\n",
    "from IPython.display import IFrame\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import random \n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory   = os.path.join('.', 'data')\n",
    "\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "df_list = [\n",
    "    pd.read_csv(os.path.join(directory, csv_file))\n",
    "    for csv_file in csv_files\n",
    "]\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "for csv in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory, csv))\n",
    "    df_list.append(df)\n",
    "\n",
    "# For sentiment analysis \n",
    "sia = SIA() \n",
    "\n",
    "# To identify misspelled words\n",
    "spell = SpellChecker() \n",
    "\n",
    "# To display plotly graphs \n",
    "pyo.init_notebook_mode() \n",
    "\n",
    "# Storing csv dataset into a datframe\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data['original_tweet'] = df['text']\n",
    "data['datetime'] = data['tweet_created']\n",
    "data['datetime'] = data.datetime.apply(lambda x: dateutil.parser.parse(x))\n",
    "rt_mask = data.text.apply(lambda x: \"RT @\" in x)\n",
    "\n",
    "# standard tweet preprocessing \n",
    "data.text = data.text.str.lower()\n",
    "#Remove twitter handlers\n",
    "data.text = data.text.apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "#remove hashtags\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
    "# Remove URLS\n",
    "data.text = data.text.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "# Remove all the special characters\n",
    "data.text = data.text.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n",
    "#remove all single characters\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "# Substituting multiple spaces with single space\n",
    "data.text = data.text.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n",
    "\n",
    "# convert the 'date' column to datetime format and remove the timezone information\n",
    "data['datetime'] = pd.to_datetime(data['datetime']).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "# Viewing the preprocessed data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(x: float):\n",
    "    if x < -0.05:\n",
    "        return 'negative'\n",
    "    if x > 0.35:\n",
    "        return 'positive'\n",
    "    return 'neutral'\n",
    "\n",
    "# Feature Extraction\n",
    "data['words'] = data.text.apply(lambda txt: re.findall(r'\\w+', txt))\n",
    "data['errors'] = data.words.apply(spell.unknown)\n",
    "data['errors_count'] = data.errors.apply(len)\n",
    "data['words_count'] = data.words.apply(len)\n",
    "data['sentence_length'] = data.text.apply(len)\n",
    "data['hour'] = data.datetime.apply(lambda dt: dt.hour)\n",
    "data['date'] = data.datetime.apply(lambda dt: dt.date())\n",
    "data['month'] = data.datetime.apply(lambda dt: dt.month)\n",
    "data['year'] = data.datetime.apply(lambda dt: dt.year)\n",
    "\n",
    "# Extract Sentiment Values for each tweet \n",
    "data['sentiment'] = [\n",
    "    sia.polarity_scores(txt)['compound'] \n",
    "    for txt in tqdm(data['text'], desc=\"Sentiment pass\")\n",
    "]\n",
    "data['overall_sentiment'] = data['sentiment'].apply(label_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
